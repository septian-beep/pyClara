{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           x           y   Name\n",
      "0  -6.248912  106.996951    Od1\n",
      "1  -6.198516  106.841202    Dd1\n",
      "2  -6.307923  107.172085    Od2\n",
      "3  -6.244686  106.800636    Dd2\n",
      "4  -6.268171  107.062801    Od3\n",
      "5  -6.196036  106.833080    Dd3\n",
      "6  -6.300809  106.652065    Od4\n",
      "7  -6.160372  106.847338    Dd4\n",
      "8  -6.202361  106.811938    Od5\n",
      "9  -6.293981  106.823737    Dd5\n",
      "10 -6.212559  106.851763    Od6\n",
      "11 -6.255341  106.855039    Dd6\n",
      "12 -6.244392  106.776544    Od7\n",
      "13 -6.231860  106.847338    Dd7\n",
      "14 -6.217303  106.903399    Od8\n",
      "15 -6.306055  106.850295    Dd8\n",
      "16 -6.193170  106.828184    Od9\n",
      "17 -6.407883  106.794241    Dd9\n",
      "18 -6.303189  106.820787   Od10\n",
      "19 -6.356632  106.879792   Dd10\n",
      "20 -6.323344  106.973645   Od11\n",
      "21 -6.369138  106.826043   Dd11\n",
      "22 -6.238341  106.998007   Od12\n",
      "23 -6.194703  106.817038   Dd12\n",
      "24 -6.371305  106.910379   Od13\n",
      "25 -6.169404  106.789102   Dd13\n",
      "26 -6.364355  106.820233   Od14\n",
      "27 -6.202767  106.811633   Dd14\n",
      "28 -6.241305  106.628483   Od15\n",
      "29 -6.228429  107.000681   Dd15\n",
      "..       ...         ...    ...\n",
      "50 -6.336153  106.763802   O R6\n",
      "51 -6.388273  106.901844   D R6\n",
      "52 -6.298251  107.050992   O R7\n",
      "53 -6.172574  106.952062   D R7\n",
      "54 -6.175392  106.827153   O R8\n",
      "55 -6.214064  106.944250   D R8\n",
      "56 -6.292778  107.000771   O R9\n",
      "57 -6.210694  106.764395   D R9\n",
      "58 -6.265337  106.884579  O R10\n",
      "59 -6.372998  106.834803  D R10\n",
      "60 -6.410267  106.993766  O R11\n",
      "61 -6.402626  106.981213  D R11\n",
      "62 -6.381461  106.930850  O R12\n",
      "63 -6.369640  106.906535  D R12\n",
      "64 -6.332824  106.857300  O R13\n",
      "65 -6.306534  106.830852  D R13\n",
      "66 -6.294108  106.797059  O R14\n",
      "67 -6.281101  106.808029  D R14\n",
      "68 -6.270589  106.793826  O R15\n",
      "69 -6.262823  106.803046  D R15\n",
      "70 -6.245208  106.781601  O R16\n",
      "71 -6.238298  106.772785  D R16\n",
      "72 -6.227523  106.739047  O R17\n",
      "73 -6.197887  106.738550  D R17\n",
      "74 -6.182378  106.723589  O R18\n",
      "75 -6.170211  106.707120  D R18\n",
      "76 -6.141207  106.672533  O R19\n",
      "77 -6.136879  106.676117  D R19\n",
      "78 -6.100308  106.703966  O R20\n",
      "79 -6.109455  106.700109  D R20\n",
      "\n",
      "[80 rows x 3 columns]\n",
      "K-medoids starting\n",
      "Running with 100000 iterations\n",
      "Best configuration found!\n",
      "K-medoids starting\n",
      "Running with 100000 iterations\n",
      "Best configuration found!\n",
      "K-medoids starting\n",
      "Running with 100000 iterations\n",
      "Best configuration found!\n",
      "K-medoids starting\n",
      "Running with 100000 iterations\n",
      "Best configuration found!\n",
      "K-medoids starting\n",
      "Running with 100000 iterations\n",
      "Best configuration found!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class ClaraClustering:\n",
    "    \"\"\"The clara clustering algorithm.\n",
    "    Basically an iterative guessing version of k-mediods that makes things a lot faster\n",
    "    for bigger data sets.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, max_iter):\n",
    "        \"\"\"Class initialization.\n",
    "        :param max_iter: The default number of max iterations\n",
    "        \"\"\"\n",
    "        self.max_iter = max_iter\n",
    "        self.dist_cache = dict()\n",
    "\n",
    "    def clara(self, _df, _k, _fn):\n",
    "        \"\"\"The main clara clustering iterative algorithm.\n",
    "        :param _df: Input data frame.\n",
    "        :param _k: Number of medoids.\n",
    "        :param _fn: The distance function to use.\n",
    "        :return: The minimized cost, the best medoid choices and the final configuration.\n",
    "        \"\"\"\n",
    "        size = len(_df)\n",
    "        if size > 100000:\n",
    "            niter = 1000\n",
    "            runs = 1\n",
    "        else:\n",
    "            niter = self.max_iter\n",
    "            runs = 5\n",
    "\n",
    "        min_avg_cost = np.inf\n",
    "        best_choices = []\n",
    "        best_results = {}\n",
    "\n",
    "        for j in range(runs):\n",
    "            sampling_idx = random.sample([i for i in range(size)], (40+_k*2))\n",
    "            sampling_data = []\n",
    "            for idx in sampling_idx:\n",
    "                sampling_data.append(_df.iloc[idx])\n",
    "\n",
    "            sampled_df = pd.DataFrame(sampling_data)\n",
    "            pre_cost, pre_choice, pre_medoids = self.k_medoids(sampled_df, _k, _fn, niter)\n",
    "            tmp_avg_cost, tmp_medoids = self.average_cost(_df, _fn, pre_choice)\n",
    "            if tmp_avg_cost <= min_avg_cost:\n",
    "                min_avg_cost = tmp_avg_cost\n",
    "                best_choices = list(pre_choice)\n",
    "                best_results = dict(tmp_medoids)\n",
    "\n",
    "        return min_avg_cost, best_choices, best_results\n",
    "\n",
    "    def k_medoids(self, _df, _k, _fn, _niter):\n",
    "        \"\"\"The original k-mediods algorithm.\n",
    "        :param _df: Input data frame.\n",
    "        :param _k: Number of medoids.\n",
    "        :param _fn: The distance function to use.\n",
    "        :param _niter: The number of iterations.\n",
    "        :return: Cluster label.\n",
    "        Pseudo-code for the k-mediods algorithm.\n",
    "        1. Sample k of the n data points as the medoids.\n",
    "        2. Associate each data point to the closest medoid.\n",
    "        3. While the cost of the data point space configuration is decreasing.\n",
    "            1. For each medoid m and each non-medoid point o:\n",
    "                1. Swap m and o, recompute cost.\n",
    "                2. If global cost increased, swap back.\n",
    "        \"\"\"\n",
    "        print('K-medoids starting')\n",
    "        # Do some smarter setting of initial cost configuration\n",
    "        pc1, medoids_sample = self.cheat_at_sampling(_df, _k, _fn, 17)\n",
    "        prior_cost, medoids = self.compute_cost(_df, _fn, medoids_sample)\n",
    "        current_cost = prior_cost\n",
    "        iter_count = 0\n",
    "        best_choices = []\n",
    "        best_results = {}\n",
    "\n",
    "        print('Running with {m} iterations'.format(m=_niter))\n",
    "        while iter_count < _niter:\n",
    "            for m in medoids:\n",
    "                clust_iter = 0\n",
    "                for item in medoids[m]:\n",
    "                    if item != m:\n",
    "                        idx = medoids_sample.index(m)\n",
    "                        swap_temp = medoids_sample[idx]\n",
    "                        medoids_sample[idx] = item\n",
    "                        tmp_cost, tmp_medoids = self.compute_cost(_df, _fn, medoids_sample, True)\n",
    "                        if (tmp_cost < current_cost) & (clust_iter < 1):\n",
    "                            best_choices = list(medoids_sample)\n",
    "                            best_results = dict(tmp_medoids)\n",
    "                            current_cost = tmp_cost\n",
    "                            clust_iter += 1\n",
    "                        else:\n",
    "                            best_choices = best_choices\n",
    "                            best_results = best_results\n",
    "                            current_cost = current_cost\n",
    "                        medoids_sample[idx] = swap_temp\n",
    "\n",
    "            iter_count += 1\n",
    "            if best_choices == medoids_sample:\n",
    "                print('Best configuration found!')\n",
    "                break\n",
    "\n",
    "            if current_cost <= prior_cost:\n",
    "                prior_cost = current_cost\n",
    "                medoids = best_results\n",
    "                medoids_sample = best_choices\n",
    "\n",
    "        return current_cost, best_choices, best_results\n",
    "\n",
    "    def compute_cost(self, _df, _fn, _cur_choice, cache_on=True):\n",
    "        \"\"\"A function to compute the configuration cost.\n",
    "        :param _df: The input data frame.\n",
    "        :param _fn: The distance function.\n",
    "        :param _cur_choice: The current set of medoid choices.\n",
    "        :param cache_on: Binary flag to turn caching.\n",
    "        :return: The total configuration cost, the mediods.\n",
    "        \"\"\"\n",
    "        size = len(_df)\n",
    "        total_cost = 0.0\n",
    "        medoids = {}\n",
    "        for idx in _cur_choice:\n",
    "            medoids[idx] = []\n",
    "\n",
    "        for i in range(size):\n",
    "            choice = -1\n",
    "            min_cost = np.inf\n",
    "            for m in medoids:\n",
    "                if cache_on:\n",
    "                    tmp = self.dist_cache.get((m, i), None)\n",
    "\n",
    "                if not cache_on or tmp is None:\n",
    "                    if _fn == 'manhattan':\n",
    "                        tmp = self.manhattan_distance(_df.iloc[m], _df.iloc[i])\n",
    "                    elif _fn == 'cosine':\n",
    "                        tmp = self.cosine_distance(_df.iloc[m], _df.iloc[i])\n",
    "                    elif _fn == 'euclidean':\n",
    "                        tmp = self.euclidean_distance(_df.iloc[m], _df.iloc[i])\n",
    "                    elif _fn == 'fast_euclidean':\n",
    "                        tmp = self.fast_euclidean(_df.iloc[m], _df.iloc[i])\n",
    "                    else:\n",
    "                        print('You need to input a distance function.')\n",
    " \n",
    "                if cache_on:\n",
    "                    self.dist_cache[(m, i)] = tmp\n",
    "\n",
    "                if tmp < min_cost:\n",
    "                    choice = m\n",
    "                    min_cost = tmp\n",
    "\n",
    "            medoids[choice].append(i)\n",
    "            total_cost += min_cost\n",
    "\n",
    "        return total_cost, medoids\n",
    "\n",
    "    def average_cost(self, _df, _fn, _cur_choice):\n",
    "        \"\"\"A function to compute the average cost.\n",
    "        :param _df: The input data frame.\n",
    "        :param _fn: The distance function.\n",
    "        :param _cur_choice: The current medoid candidates.\n",
    "        :return: The average cost, the new medoids.\n",
    "        \"\"\"\n",
    "        _tc, _m = self.compute_cost(_df, _fn, _cur_choice)\n",
    "        avg_cost = _tc / len(_m)\n",
    "        return avg_cost, _m\n",
    "\n",
    "    def cheat_at_sampling(self, _df, _k, _fn, _nsamp):\n",
    "        \"\"\"A function to cheat at sampling for speed ups.\n",
    "        :param _df: The input data frame.\n",
    "        :param _k: The number of medoids.\n",
    "        :param _fn: The distance function.\n",
    "        :param _nsamp: The number of samples.\n",
    "        :return: The best score, the medoids.\n",
    "        \"\"\"\n",
    "        size = len(_df)\n",
    "        score_holder = []\n",
    "        medoid_holder = []\n",
    "        for _ in range(_nsamp):\n",
    "            medoids_sample = random.sample([i for i in range(size)], _k)\n",
    "            prior_cost, medoids = self.compute_cost(_df, _fn, medoids_sample, True)\n",
    "            score_holder.append(prior_cost)\n",
    "            medoid_holder.append(medoids)\n",
    "\n",
    "        idx = score_holder.index(min(score_holder))\n",
    "        ms = medoid_holder[idx].keys()\n",
    "        return score_holder[idx], ms\n",
    "\n",
    "    def euclidean_distance(self, v1, v2):\n",
    "        \"\"\"Slow function for euclidean distance.\n",
    "        :param v1: The first vector.\n",
    "        :param v2: The second vector.\n",
    "        :return: The euclidean distance between v1 and v2.\n",
    "        \"\"\"\n",
    "        dist = 0\n",
    "        for a1, a2 in zip(v1, v2):\n",
    "            dist += abs(a1 - a2)**2\n",
    "        return dist\n",
    "\n",
    "    def fast_euclidean(self, v1, v2):\n",
    "        \"\"\"Faster function for euclidean distance.\n",
    "        :param v1: The first vector.\n",
    "        :param v2: The second vector.\n",
    "        :return: The euclidean distance between v1 and v2.\n",
    "        \"\"\"\n",
    "        return np.linalg.norm(v1 - v2)\n",
    "\n",
    "    def manhattan_distance(self, v1, v2):\n",
    "        \"\"\"Function for manhattan distance.\n",
    "        :param v1: The first vector.\n",
    "        :param v2: The second vector.\n",
    "        :return: The manhattan distance between v1 and v2.\n",
    "        \"\"\"\n",
    "        dist = 0\n",
    "        for a1, a2 in zip(v1, v2):\n",
    "            dist += abs(a1 - a2)\n",
    "        return dist\n",
    "\n",
    "    def cosine_distance(self, v1, v2):\n",
    "        \"\"\"Function for cosine distance.\n",
    "        :param v1: The first vector.\n",
    "        :param v2: The second vector.\n",
    "        :return: The cosine distance between v1 and v2.\n",
    "        \"\"\"\n",
    "        xx, yy, xy = 0, 0, 0\n",
    "        for a1, a2 in zip(v1, v2):\n",
    "            xx += a1*a1\n",
    "            yy += a2*a2\n",
    "            xy += a1*a2\n",
    "        return float(xy) / np.sqrt(xx*yy)\n",
    "\n",
    "data = pd.read_csv(\"E:\\Kak Lia\\koordinat.csv\") #Load data berformat .csv berdasarkan lokasi file\n",
    "print data\n",
    "ridesharing = data.drop([\"Name\"], axis=1) #Menghapus attribute data koordinat yang tidak diperlukan\n",
    "dist = 'euclidean' #metode distance ['euclidean','fast_euclidean','manhattan','cosine']\n",
    "max_i=100000\n",
    "CLARA = ClaraClustering(max_i)\n",
    "out = CLARA.clara(ridesharing, 5, dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0902235880506\n",
      "[14, 0, 20, 32, 3]\n",
      "{0: [0, 1, 6, 8, 16, 37, 40, 41, 46, 52], 32: [11, 15, 21, 23, 24, 28, 32, 35, 36, 38, 48, 54, 57, 73, 74, 75, 76, 77, 78, 79], 3: [2, 3, 4, 5, 7, 9, 10, 12, 17, 26, 30, 31, 34, 42, 44, 47, 50, 59, 64, 65, 66, 67, 68, 69, 70, 71, 72], 20: [13, 18, 19, 20, 22, 27, 29, 33, 39, 43, 45, 49, 51, 56, 60, 61, 62, 63], 14: [14, 25, 53, 55, 58]}\n"
     ]
    }
   ],
   "source": [
    "for x in out:\n",
    "    print x #Memapilkan hasil Cluster dari algoritma Clara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
